{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GtJGFWTKOFSl"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehudb9/N1X10_dev/blob/ehud/document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJGFWTKOFSl"
      },
      "source": [
        "**Documet Classification class:** \n",
        "\n",
        "__Author : Ehud Barda \n",
        "\n",
        " gets path to file (mode=PDF)  or txt file (mode=TXT)and output set of index that describe and verify the file.\n",
        " procedure check that the file belongs to the patient, return the document relevant date (event date) and return document type out of a list of types (stored in file_type_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_9Nf4tKb0tT"
      },
      "source": [
        "# installing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_xOlersN2mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2db7b49-9c9a-45b1-9c02-de4903af2d08"
      },
      "source": [
        "# Tesseract dependencies\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev\n",
        "# Poppler  dependencies\n",
        "!apt-get install poppler-utils\n",
        "!pip install pdf2image\n",
        "!python -m pip install pypdf2\n",
        "!pip install pdfminer\n",
        "!pip install tika\n",
        "\n",
        "from datetime import date\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "from IPython.display import display, Image\n",
        "\n",
        "!pip install PyPDF2\n",
        "from PyPDF2 import PdfFileReader\n",
        "from google.colab import drive\n",
        "\n",
        "from tika import parser\n",
        "import PyPDF2\n",
        "import re\n",
        "import yaml\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from io import StringIO\n",
        "import time\n",
        "import csv\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import isfile, join, splitext\n",
        "\n",
        "print('\\n\\nTesseract Version:', pytesseract.get_tesseract_version())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (0.62.0-2ubuntu2.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.7/dist-packages (1.15.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n",
            "Requirement already satisfied: pdfminer in /usr/local/lib/python3.7/dist-packages (20191125)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from pdfminer) (3.10.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.7/dist-packages (1.24)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (57.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2020.12.5)\n",
            "\n",
            "\n",
            "Tesseract Version: 4.0.0-beta.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYGONBmaPT4p"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxKXfPv-b-9A"
      },
      "source": [
        "# constans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6MSQBtiRJOS"
      },
      "source": [
        "CONSTANS: need to move to dict files and impot it to here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmkJvLigRE6v"
      },
      "source": [
        "# CONSTANS: need to move to dict files and impot it to here\n",
        "\n",
        "\n",
        "procedure_types_EXP = {\n",
        "    'Pathology and Surgery': [\"Pathology\", \"CYTOPATHOLOGY\", \"Surgical Procedure\", \"SURGICAL\", \"Surgical\", \"PATHOLOGY\"],\n",
        "    \"Medication prescriptions\": [\"Medication\", \"Medications\"],\n",
        "    \"Imaging\": [\"CT\", \"XR\", \"NM\", \"FDG\", \"PET/CT\", \"PET\", 'XR', 'MRI', 'PET CT', 'CT', 'DOTATATE'],\n",
        "    \"Blood Test\": [\"Collection Information\", \"METABOLIC\", \"LAB RESULT\"],\n",
        "    \"Dr summaries\": [\"\"],\n",
        "    \"Hospital release forms\": [\"\"],\n",
        "    \"Medication prescriptions\": [\"\"],\n",
        "}\n",
        "TITLES = [\"report\", \"summery\", \"result\"]\n",
        "DOC_DATE = [\"date of report\"]\n",
        "date_of_procedure = [\"Collection\", \"collected\", \"s\" ]\n",
        "institution_list = [\"\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO4b6h1UcDds"
      },
      "source": [
        "# document class\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl6ugJchRBYF"
      },
      "source": [
        "the class get path to pdf and open it to extract the indexes:\n",
        "\n",
        "need to be change to .txt input withput haldle the pdf obj."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTrf6mQORAGF"
      },
      "source": [
        "# the class get path to pdf and open it to extract the indexes:\n",
        "\n",
        "# need to be change to .txt input withput haldle the pdf obj.\n",
        "\n",
        "class DocumentClassification:\n",
        "    \"\"\"\n",
        "\n",
        "    gets path to file (mode=\"PDF\")  or txt file (mode=\"TXT\")and output set of index that describe and verify the file.\n",
        "    procedure check that the file belongs to the patient,\n",
        "    return the document relevant date (event date) and\n",
        "    return document type out of a list of types (stored in file_type_list)\n",
        "\n",
        "    :param str: path to file\n",
        "    :param (optional)str: patient full name\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, file=None, patient_name=None, mode=\"TXT\"):\n",
        "        self.mode = mode\n",
        "        self.path = path\n",
        "        self.patient_name = patient_name\n",
        "        page_num = 0\n",
        "        \n",
        "        if mode == \"PDF\":\n",
        "          self.pdf_mode = \"pdfObj\"\n",
        "          # Need to be replace with txt input\n",
        "          with open(self.path, \"rb\") as self.f:\n",
        "              reader = PyPDF2.PdfFileReader(self.f)\n",
        "              page = reader.getPage(0)\n",
        "              page_num = reader.getNumPages()\n",
        "              self.read_pdf = page.extractText()\n",
        "\n",
        "          if len(self.read_pdf) < 10:\n",
        "              self.read_pdf = self.convert_pdf_to_txt(self.path)\n",
        "              self.pdf_mode = \"hackPdf\"\n",
        "              if len(self.read_pdf) < 10 or self.read_pdf[0] == \"(\":\n",
        "                  # ocr\n",
        "                  print(\"---------____needed to acrivate OCR mode____---------\\n\\n\\n\\n\")\n",
        "                  self.pdf_mode = \"OCR\"\n",
        "                  # TBC on colab\n",
        "                  self.read_pdf = self.ocr_convert_pdf_to_str(file)\n",
        "        # if input TXT file\n",
        "        else: \n",
        "          self.read_pdf = file\n",
        "    \n",
        "        #remove empty lines for better accuracy\n",
        "        self.remove_empty_lines()\n",
        "\n",
        "        self.doc_index = { \n",
        "            \"patient_name\": self.get_patient_name(), \n",
        "            \"date_of_document\": self.get_doc_date(),  #TBC\n",
        "            \"date_of_procedure\": self.get_procedure_date(), #TBC\n",
        "            \"doctor_name\": self.get_doctor_name(),\n",
        "            # \"department\": self.get_department(),\n",
        "            \"institution\": self.get_get_institution_name(),  #TBC\n",
        "            \"procedure_type\": self.extract_type(),  #TBC\n",
        "            \"num_of_pages\": page_num,  #need to add assignment when is TXT given\n",
        "            \"document_reference\": self.path\n",
        "        }\n",
        "\n",
        "    def close_file(self):\n",
        "        \"\"\"\n",
        "\n",
        "        close the file obj\n",
        "        \"\"\"\n",
        "        self.f.close()\n",
        "\n",
        "    def get_doc_index(self):\n",
        "        \"\"\"\n",
        "        # to print use:\n",
        "        # import yaml\n",
        "        # print(yaml.dump(a.get_doc_index()))\n",
        "\n",
        "\n",
        "        :return: dict: the given doc_index\n",
        "        \"\"\"\n",
        "        return self.doc_index\n",
        "        \n",
        "\n",
        "    def remove_empty_lines(self):\n",
        "        \"\"\"\n",
        "        rempves empty line in the text\n",
        "        \"\"\"\n",
        "        lines = self.read_pdf.split(\"\\n\")\n",
        "        non_empty_lines = [line for line in lines if line.strip() != \"\"]\n",
        "        string_without_empty_lines = \"\"\n",
        "        for line in non_empty_lines:\n",
        "            string_without_empty_lines += line + \"\\n\"\n",
        "\n",
        "        self.read_pdf = string_without_empty_lines\n",
        "\n",
        "    def _print_index(self):\n",
        "        \"\"\"\n",
        "\n",
        "        prints the doc_index(JSON/DICT)\n",
        "        \"\"\"\n",
        "        print(yaml.dump(self.get_doc_index()))\n",
        "\n",
        "    def get_text(self) -> str:\n",
        "        \"\"\"\n",
        "        :return: str: doc text - in lower case\n",
        "        \"\"\"\n",
        "        return self.read_pdf.lower()\n",
        "\n",
        "    def get_doctor_name(self):\n",
        "        \"\"\"\n",
        "        :return: str doctor name\n",
        "        \"\"\"\n",
        "        lines = \"\\n\".join(self.read_pdf.splitlines()[2:20])\n",
        "        pattern = re.compile(r'([A-Z]\\w+[^:\\n]+)\\s(MD|M\\.D\\.)')\n",
        "        search = re.search(pattern, lines)\n",
        "        if search:\n",
        "            return search.group()\n",
        "\n",
        "    def get_get_institution_name(self):\n",
        "        \"\"\"\n",
        "        # problem with read from pictures -TBC\n",
        "        :return: str :  institution_name\n",
        "        \"\"\"\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def get_doc_date(self):\n",
        "        pass\n",
        "\n",
        "    def get_procedure_date(self):\n",
        "        pass\n",
        "\n",
        "    def convert_pdf_to_txt(self, path) -> str:\n",
        "        \"\"\"\n",
        "        read pdf file and conevt the text to str using pdfminer\n",
        "        :param path: file input\n",
        "        :return: str: file's text in str\n",
        "        \"\"\"\n",
        "        rsrcmgr = PDFResourceManager()\n",
        "        retstr = StringIO()\n",
        "        codec = 'utf-8'\n",
        "        laparams = LAParams()\n",
        "        device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
        "        fp = open(path, 'rb')\n",
        "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "        password = \"\"\n",
        "        maxpages = 0\n",
        "        caching = True\n",
        "        pagenos = set()\n",
        "\n",
        "        for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching,\n",
        "                                      check_extractable=True):\n",
        "            interpreter.process_page(page)\n",
        "\n",
        "        text = retstr.getvalue()\n",
        "\n",
        "        fp.close()\n",
        "        device.close()\n",
        "        retstr.close()\n",
        "        return text\n",
        "\n",
        "    def ocr_pdf_to_str(self, path):\n",
        "        \"\"\"\n",
        "        MUST CONNECT TO OCR MODULE\n",
        "        :return: str : file text\n",
        "        \"\"\"\n",
        "        str_lst = [\"CONNECT\", \"OCR\", \"!\"]\n",
        "        # img_lst = convert_pdf_to_image_list(path)\n",
        "        # str_lst = convert_list_of_images_to_list_of_str(img_lst)\n",
        "        txt = '\\n'.join([i for i in str_lst[1:]])\n",
        "        return txt\n",
        "\n",
        "    def extract_type(self):\n",
        "        \"\"\"\n",
        "        Go through the first 15 lines and get the type\n",
        "        from a constant list of types\n",
        "\n",
        "        :return: str : document type\n",
        "        \"\"\"\n",
        "        lines = self.get_text().splitlines()\n",
        "        num_line = 2\n",
        "        types = {}\n",
        "        for line in lines[2:15]:\n",
        "            for type in procedure_types_EXP:\n",
        "                for term in procedure_types_EXP[type]:\n",
        "                    words = line.split()\n",
        "                    for word in words:\n",
        "                        if word == term.lower():\n",
        "                            types[num_line] = type\n",
        "\n",
        "            num_line += 1\n",
        "        if len(types) == 0:\n",
        "            return None\n",
        "        return (min(types.items(), key=lambda x: x[0])[1])\n",
        "\n",
        "    def search_line_index(self, word):\n",
        "        \"\"\"\n",
        "        search for a given word in self.text\n",
        "        return the line index where the word found. and -1 if wasn't found\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def get_patient_name(self):\n",
        "        \"\"\"\n",
        "        Check if a given patient name is correct\n",
        "        and set the name if was't given a name\n",
        "        \"\"\"\n",
        "        if self.patient_name is None:\n",
        "            match = re.search(r'(patient|name|patient name): (\\w+\\s\\w+)', self.read_pdf.lower())\n",
        "            if match:\n",
        "                return match.group(2)\n",
        "            else:\n",
        "                return \"No name\"\n",
        "        name = self.patient_name.split()\n",
        "        i = 0\n",
        "        lines = self.get_text().splitlines()\n",
        "        for line in lines[2:15]:\n",
        "            list_line = line.split()\n",
        "            for a in name:\n",
        "                if a in list_line:\n",
        "                    i +=1\n",
        "            if i == len(name):\n",
        "                return self.patient_name\n",
        "            i = 0\n",
        "        return \"no name\"\n",
        "\n",
        "\n",
        "    #   for colab- calling ocr methods\n",
        "    def ocr_convert_pdf_to_str(self, path):\n",
        "        img_lst = self.convert_pdf_to_image_list(path)\n",
        "        str_lst = self.convert_list_of_images_to_list_of_str(img_lst)\n",
        "        txt = '\\n'.join([i for i in str_lst[1:]])\n",
        "        return txt\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8GrwoqcUZDV"
      },
      "source": [
        "OCR FUNCTIONS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtyTZ6ciUduQ"
      },
      "source": [
        "def convert_pdf_to_image_list(pdf_path):\n",
        "    \"\"\"\n",
        "        this function converts pdf to a python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        pdf_path : string\n",
        "            pdf_path is the local path of the pdf file on given machine.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images,\n",
        "            where each image corresponds to a single pdf page.\n",
        "\n",
        "        \"\"\"\n",
        "    pages = convert_from_path(pdf_path, 300)  # pages is a list of images\n",
        "    return pages\n",
        "\n",
        "\n",
        "def convert_list_of_images_to_list_of_str(img_lst):\n",
        "    \"\"\"\n",
        "        this function converts a list of images to a list of strings.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_lst : Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Python list\n",
        "            Python list of strings corresponding to img_lst.\n",
        "\n",
        "        \"\"\"\n",
        "    lst_of_str = []\n",
        "    for img in img_lst:\n",
        "        lst_of_str.append(pytesseract.image_to_string(img))\n",
        "    return lst_of_str\n",
        "\n",
        "\n",
        "def convert_list_of_images_to_list_of_xml(img_lst):\n",
        "    \"\"\"\n",
        "        this function converts a list of images to a list of xml (type=byte).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_lst : Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Python list\n",
        "            Python list of xml(type=byte) corresponding to img_lst.\n",
        "\n",
        "        \"\"\"\n",
        "    lst_of_xml = []\n",
        "    for img in img_lst:\n",
        "        lst_of_xml.append(pytesseract.image_to_pdf_or_hocr(img, extension='hocr'))  # Get HOCR output)\n",
        "    return lst_of_xml\n",
        "\n",
        "\n",
        "def convert_list_of_images_to_list_of_data(img_lst):\n",
        "    \"\"\"\n",
        "        this function converts a list of images to a list of tables of data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_lst : Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Python list\n",
        "            Python list of tables of data corresponding to img_lst.\n",
        "\n",
        "        \"\"\"\n",
        "    lst_of_data = []\n",
        "    for img in img_lst:\n",
        "        lst_of_data.append(pytesseract.image_to_data(img))\n",
        "    return lst_of_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuioIG84cSiz"
      },
      "source": [
        "# files creator\n",
        "running on a given path and creating CSV file with the result on document class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIiFc6c4VzA0"
      },
      "source": [
        "Callingand creating files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5UNXU8YXcsT"
      },
      "source": [
        "class file_creator:\n",
        "  \"\"\"\n",
        "  creat csv file with document indexes\n",
        "  using Dpcument classification class \n",
        "  \"\"\"\n",
        "  def __init__(self, path=None):\n",
        "    drive.mount('/content/drive')\n",
        "    # Drive path:\n",
        "    self.test_path = r'/content/drive/Shareddrives/co-op_projects/Sample documents/'\n",
        "    self.main_dir = path\n",
        "    if path == None:\n",
        "      self.main_dir = self.test_path\n",
        "    self.sub_dirs = [join(self.main_dir , f) for f in listdir(self.main_dir) if not isfile(join(self.main_dir , f))]\n",
        "    \n",
        "    # dir1 = r'Sample documents/'\n",
        "    # dir2 = r'Blood tests/'\n",
        "    # self.mypath = self.test_path+dir1+dir2\n",
        "\n",
        "  def list_sub_dir_fullpath(self):\n",
        "    return [join(self.main_dir, f) for f in os.listdir(self.main_dir) if not isfile(join(self.main_dir, f))]\n",
        "\n",
        "  def get_list_of_only_files(self):\n",
        "    onlyfiles = [f for f in listdir(self.main_dir) if isfile(join(mypath, f))]\n",
        "    return onlyfiles\n",
        "  \n",
        "  def doc_index_to_CSV(self, file):\n",
        "    pass\n",
        "  \n",
        "  def run(self):\n",
        "    # each type\n",
        "    for dir in self.sub_dirs:\n",
        "      # doc dirs\n",
        "      doc_sub_dir = [join(dir , f) for f in listdir(dir) if not isfile(join(dir , f))]\n",
        "      for doc in doc_sub_dir:\n",
        "        # print(doc)\n",
        "        #current ocr_txt\n",
        "        ocr_file = doc+\"/OCR_txt_all.txt\"\n",
        "        with open(ocr_file, 'r') as file:\n",
        "            ocr_txt =\" \".join(file.readlines())\n",
        "        doc_class = DocumentClassification(p+\".pdf\", file=ocr_txt, patient_name=None, mode='TXT')\n",
        "        indexes = doc_class.get_doc_index()\n",
        "        now = datetime.now()\n",
        "        # dd/mm/YY H:M:S\n",
        "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "        indexes[\"Last modified\"] = dt_string\n",
        "        # TBC: write in the current doc path \"doc_index.csv\"\n",
        "        # TBC: ADD row with the \"indexes\" to the global doc index\n",
        "\n",
        "\n",
        "        # onlyTxtFiles = [f for f in listdir(p) if isfile(join(p, f)) and  f.endswith(\".txt\")]\n",
        "        # # working_on_first_txt_file\n",
        "        # working_on_first_txt_file = p+\"/\"+onlyTxtFiles[0]\n",
        "        # print(working_on_first_txt_file)\n",
        "        # with open(working_on_first_txt_file, 'r') as file:\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O19Jo-HNV3du"
      },
      "source": [
        "a=file_creator()\n",
        "print(a.run())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDUMBUTpc0Mv"
      },
      "source": [
        "# TESTER:: RUN THE PROGRAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jy1DKUnRgSc"
      },
      "source": [
        "a=file_creator()\n",
        "a.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmMlhhc8ctv3"
      },
      "source": [
        "# draft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdN5b2N8WP4J"
      },
      "source": [
        "draft cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMqzfgxyc6dT",
        "outputId": "b20106b8-19f2-46ab-a5c0-4e8b53137bb6"
      },
      "source": [
        "# a = DocumentClassification(r\"C:\\Users\\ehudb\\PycharmProjects\\nixio test\\Sample documents\\Pathology\\2016.4.14. Brigham slide review.pdf\")\n",
        "# # print(a.print_indexs)\n",
        "# print(yaml.dump(a.get_doc_index()))\n",
        "# a.close_file()\n",
        "\n",
        "a = DocumentClassification(r\"/content/drive/Shareddrives/co-op_projects/Sample documents/Pathology/2019.6.26. endobronchial bx.pdf\" , mode=\"PDF\")\n",
        "#print(a._print_index())\n",
        "print(yaml.dump(a.get_doc_index()))\n",
        "# print(a.read_pdf)\n",
        "\n",
        "a.close_file()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{date_of_document: null, date_of_procedure: null, doctor_name: 'Chalker, Richard Bruce,\n",
            "    MD', document_reference: /content/drive/Shareddrives/co-op_projects/Sample documents/Pathology/2019.6.26.\n",
            "    endobronchial bx.pdf, institution: null, num_of_pages: 3, patient_name: No name,\n",
            "  procedure_type: Pathology and Surgery}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6kJn9HmWVLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f983ed-6872-43e5-e8bb-26e0b5f697b0"
      },
      "source": [
        "# working cell:\n",
        "test_path = r'/content/drive/Shareddrives/co-op_projects/Sample documents/'\n",
        "\n",
        "sub_dir = [join(test_path , f) for f in listdir(test_path) if not isfile(join(test_path , f))]\n",
        "\n",
        "p = r\"/content/drive/Shareddrives/co-op_projects/Sample documents/Imaging/EM imaging\"\n",
        "# print(listdir(p))\n",
        "\n",
        "# ocr_txt\n",
        "ocr_file = p+\"/OCR_txt_all.txt\"\n",
        "with open(ocr_file, 'r') as file:\n",
        "    ocr_txt =\" \".join(file.readlines())\n",
        "doc = DocumentClassification(p+\".pdf\", file=ocr_txt, patient_name=None, mode='TXT')\n",
        "indexes = doc.get_doc_index()\n",
        "now = datetime.now()\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "indexes[\"Last modified\"] = dt_string\n",
        "\n",
        "# print(indexes.keys)\n",
        "print(indexes)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# a = DocumentClassification(p+\".pdf\" , mode=\"PDF\")\n",
        "# #print(a._print_index())\n",
        "# print(yaml.dump(a.get_doc_index()))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patient_name': 'No name', 'date_of_document': None, 'date_of_procedure': None, 'doctor_name': 'JOEL SHEINFELD, MD', 'institution': None, 'procedure_type': 'Imaging', 'num_of_pages': 0, 'document_reference': '/content/drive/Shareddrives/co-op_projects/Sample documents/Imaging/EM imaging.pdf', 'Last modified': '08/06/2021 15:24:23'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYQYR_pTMyaC",
        "outputId": "2939cd44-6d71-4180-a68e-09d85eb42f3c"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        " \n",
        "print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now = 2021-06-08 15:17:28.055767\n",
            "date and time = 08/06/2021 15:17:28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkaWPHzQKqg"
      },
      "source": [
        "field_names = ['No', 'Company', 'Car Model']\n",
        "  \n",
        "cars = [\n",
        "{'No': 1, 'Company': 'Ferrari', 'Car Model': '488 GTB'},\n",
        "{'No': 2, 'Company': 'Porsche', 'Car Model': '918 Spyder'},\n",
        "{'No': 3, 'Company': 'Bugatti', 'Car Model': 'La Voiture Noire'},\n",
        "{'No': 4, 'Company': 'Rolls Royce', 'Car Model': 'Phantom'},\n",
        "{'No': 5, 'Company': 'BMW', 'Car Model': 'BMW X7'},\n",
        "]\n",
        "  \n",
        "with open('Names.csv', 'w') as csvfile:\n",
        "    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n",
        "    writer.writeheader()\n",
        "    writer.writerows(cars)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRRJzeKSNdUR"
      },
      "source": [
        "indexes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCOIzNxRHncI"
      },
      "source": [
        "print(ocr_txt)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}