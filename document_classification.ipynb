{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "document_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GtJGFWTKOFSl",
        "6_9Nf4tKb0tT",
        "gxKXfPv-b-9A",
        "EO4b6h1UcDds",
        "GmMlhhc8ctv3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehudb9/N1X10_dev/blob/develop/document_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJGFWTKOFSl"
      },
      "source": [
        "**Documet Classification class:** \n",
        "\n",
        "__Author : Ehud Barda \n",
        "\n",
        " gets path to file (mode=PDF)  or txt file (mode=TXT)and output set of index that describe and verify the file.\n",
        " procedure check that the file belongs to the patient, return the document relevant date (event date) and return document type out of a list of types (stored in file_type_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_9Nf4tKb0tT"
      },
      "source": [
        "# installing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_xOlersN2mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2db7b49-9c9a-45b1-9c02-de4903af2d08"
      },
      "source": [
        "# Tesseract dependencies\n",
        "!pip install pytesseract\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev\n",
        "# Poppler  dependencies\n",
        "!apt-get install poppler-utils\n",
        "!pip install pdf2image\n",
        "!python -m pip install pypdf2\n",
        "!pip install pdfminer\n",
        "!pip install tika\n",
        "\n",
        "from datetime import date\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "from google.colab import drive\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image\n",
        "\n",
        "from pdf2image import convert_from_path, convert_from_bytes\n",
        "from IPython.display import display, Image\n",
        "\n",
        "!pip install PyPDF2\n",
        "from PyPDF2 import PdfFileReader\n",
        "from google.colab import drive\n",
        "\n",
        "from tika import parser\n",
        "import PyPDF2\n",
        "import re\n",
        "import yaml\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from io import StringIO\n",
        "import time\n",
        "import csv\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "from os import listdir\n",
        "from os.path import isfile, join, splitext\n",
        "\n",
        "print('\\n\\nTesseract Version:', pytesseract.get_tesseract_version())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (0.62.0-2ubuntu2.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.7/dist-packages (1.15.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from pdf2image) (7.1.2)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n",
            "Requirement already satisfied: pdfminer in /usr/local/lib/python3.7/dist-packages (20191125)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from pdfminer) (3.10.1)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (1.26.0)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.7/dist-packages (1.24)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (57.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2020.12.5)\n",
            "\n",
            "\n",
            "Tesseract Version: 4.0.0-beta.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYGONBmaPT4p"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxKXfPv-b-9A"
      },
      "source": [
        "# constans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6MSQBtiRJOS"
      },
      "source": [
        "CONSTANS: need to move to dict files and impot it to here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmkJvLigRE6v"
      },
      "source": [
        "# CONSTANS: need to move to dict files and impot it to here\n",
        "\n",
        "\n",
        "procedure_types_EXP = {\n",
        "    'Pathology and Surgery': [\"Pathology\", \"CYTOPATHOLOGY\", \"Surgical Procedure\", \"SURGICAL\", \"Surgical\", \"PATHOLOGY\"],\n",
        "    \"Medication prescriptions\": [\"Medication\", \"Medications\"],\n",
        "    \"Imaging\": [\"CT\", \"XR\", \"NM\", \"FDG\", \"PET/CT\", \"PET\", 'XR', 'MRI', 'PET CT', 'CT', 'DOTATATE'],\n",
        "    \"Blood Test\": [\"Collection Information\", \"METABOLIC\", \"LAB RESULT\"],\n",
        "    \"Dr summaries\": [\"\"],\n",
        "    \"Hospital release forms\": [\"\"],\n",
        "    \"Medication prescriptions\": [\"\"],\n",
        "}\n",
        "TITLES = [\"report\", \"summery\", \"result\"]\n",
        "DOC_DATE = [\"date of report\"]\n",
        "date_of_procedure = [\"Collection\", \"collected\", \"s\" ]\n",
        "institution_list = [\"\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO4b6h1UcDds"
      },
      "source": [
        "# document class\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl6ugJchRBYF"
      },
      "source": [
        "the class get path to pdf and open it to extract the indexes:\n",
        "\n",
        "need to be change to .txt input withput haldle the pdf obj."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTrf6mQORAGF"
      },
      "source": [
        "# the class get path to pdf and open it to extract the indexes:\n",
        "\n",
        "# need to be change to .txt input withput haldle the pdf obj.\n",
        "\n",
        "class DocumentClassification:\n",
        "    \"\"\"\n",
        "\n",
        "    gets path to file (mode=\"PDF\")  or txt file (mode=\"TXT\")and output set of index that describe and verify the file.\n",
        "    procedure check that the file belongs to the patient,\n",
        "    return the document relevant date (event date) and\n",
        "    return document type out of a list of types (stored in file_type_list)\n",
        "\n",
        "    :param str: path to file\n",
        "    :param (optional)str: patient full name\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, file=None, patient_name=None, mode=\"TXT\"):\n",
        "        self.mode = mode\n",
        "        self.path = path\n",
        "        self.patient_name = patient_name\n",
        "        page_num = 0\n",
        "        \n",
        "        if mode == \"PDF\":\n",
        "          self.pdf_mode = \"pdfObj\"\n",
        "          # Need to be replace with txt input\n",
        "          with open(self.path, \"rb\") as self.f:\n",
        "              reader = PyPDF2.PdfFileReader(self.f)\n",
        "              page = reader.getPage(0)\n",
        "              page_num = reader.getNumPages()\n",
        "              self.read_pdf = page.extractText()\n",
        "\n",
        "          if len(self.read_pdf) < 10:\n",
        "              self.read_pdf = self.convert_pdf_to_txt(self.path)\n",
        "              self.pdf_mode = \"hackPdf\"\n",
        "              if len(self.read_pdf) < 10 or self.read_pdf[0] == \"(\":\n",
        "                  # ocr\n",
        "                  print(\"---------____needed to acrivate OCR mode____---------\\n\\n\\n\\n\")\n",
        "                  self.pdf_mode = \"OCR\"\n",
        "                  # TBC on colab\n",
        "                  self.read_pdf = self.ocr_convert_pdf_to_str(file)\n",
        "        # if input TXT file\n",
        "        else: \n",
        "          self.read_pdf = file\n",
        "    \n",
        "        #remove empty lines for better accuracy\n",
        "        self.remove_empty_lines()\n",
        "\n",
        "        self.doc_index = { \n",
        "            \"patient_name\": self.get_patient_name(), \n",
        "            \"date_of_document\": self.get_doc_date(),  #TBC\n",
        "            \"date_of_procedure\": self.get_procedure_date(), #TBC\n",
        "            \"doctor_name\": self.get_doctor_name(),\n",
        "            # \"department\": self.get_department(),\n",
        "            \"institution\": self.get_get_institution_name(),  #TBC\n",
        "            \"procedure_type\": self.extract_type(),  #TBC\n",
        "            \"num_of_pages\": page_num,  #need to add assignment when is TXT given\n",
        "            \"document_reference\": self.path\n",
        "        }\n",
        "\n",
        "    def close_file(self):\n",
        "        \"\"\"\n",
        "\n",
        "        close the file obj\n",
        "        \"\"\"\n",
        "        self.f.close()\n",
        "\n",
        "    def get_doc_index(self):\n",
        "        \"\"\"\n",
        "        # to print use:\n",
        "        # import yaml\n",
        "        # print(yaml.dump(a.get_doc_index()))\n",
        "\n",
        "\n",
        "        :return: dict: the given doc_index\n",
        "        \"\"\"\n",
        "        return self.doc_index\n",
        "        \n",
        "\n",
        "    def remove_empty_lines(self):\n",
        "        \"\"\"\n",
        "        rempves empty line in the text\n",
        "        \"\"\"\n",
        "        lines = self.read_pdf.split(\"\\n\")\n",
        "        non_empty_lines = [line for line in lines if line.strip() != \"\"]\n",
        "        string_without_empty_lines = \"\"\n",
        "        for line in non_empty_lines:\n",
        "            string_without_empty_lines += line + \"\\n\"\n",
        "\n",
        "        self.read_pdf = string_without_empty_lines\n",
        "\n",
        "    def _print_index(self):\n",
        "        \"\"\"\n",
        "\n",
        "        prints the doc_index(JSON/DICT)\n",
        "        \"\"\"\n",
        "        print(yaml.dump(self.get_doc_index()))\n",
        "\n",
        "    def get_text(self) -> str:\n",
        "        \"\"\"\n",
        "        :return: str: doc text - in lower case\n",
        "        \"\"\"\n",
        "        return self.read_pdf.lower()\n",
        "\n",
        "    def get_doctor_name(self):\n",
        "        \"\"\"\n",
        "        :return: str doctor name\n",
        "        \"\"\"\n",
        "        lines = \"\\n\".join(self.read_pdf.splitlines()[2:20])\n",
        "        pattern = re.compile(r'([A-Z]\\w+[^:\\n]+)\\s(MD|M\\.D\\.)')\n",
        "        search = re.search(pattern, lines)\n",
        "        if search:\n",
        "            return search.group()\n",
        "\n",
        "    def get_get_institution_name(self):\n",
        "        \"\"\"\n",
        "        # problem with read from pictures -TBC\n",
        "        :return: str :  institution_name\n",
        "        \"\"\"\n",
        "        \n",
        "        pass\n",
        "\n",
        "    def get_doc_date(self):\n",
        "        pass\n",
        "\n",
        "    def get_procedure_date(self):\n",
        "        pass\n",
        "\n",
        "    def convert_pdf_to_txt(self, path) -> str:\n",
        "        \"\"\"\n",
        "        read pdf file and conevt the text to str using pdfminer\n",
        "        :param path: file input\n",
        "        :return: str: file's text in str\n",
        "        \"\"\"\n",
        "        rsrcmgr = PDFResourceManager()\n",
        "        retstr = StringIO()\n",
        "        codec = 'utf-8'\n",
        "        laparams = LAParams()\n",
        "        device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
        "        fp = open(path, 'rb')\n",
        "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "        password = \"\"\n",
        "        maxpages = 0\n",
        "        caching = True\n",
        "        pagenos = set()\n",
        "\n",
        "        for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching,\n",
        "                                      check_extractable=True):\n",
        "            interpreter.process_page(page)\n",
        "\n",
        "        text = retstr.getvalue()\n",
        "\n",
        "        fp.close()\n",
        "        device.close()\n",
        "        retstr.close()\n",
        "        return text\n",
        "\n",
        "    def ocr_pdf_to_str(self, path):\n",
        "        \"\"\"\n",
        "        MUST CONNECT TO OCR MODULE\n",
        "        :return: str : file text\n",
        "        \"\"\"\n",
        "        str_lst = [\"CONNECT\", \"OCR\", \"!\"]\n",
        "        # img_lst = convert_pdf_to_image_list(path)\n",
        "        # str_lst = convert_list_of_images_to_list_of_str(img_lst)\n",
        "        txt = '\\n'.join([i for i in str_lst[1:]])\n",
        "        return txt\n",
        "\n",
        "    def extract_type(self):\n",
        "        \"\"\"\n",
        "        Go through the first 15 lines and get the type\n",
        "        from a constant list of types\n",
        "\n",
        "        :return: str : document type\n",
        "        \"\"\"\n",
        "        lines = self.get_text().splitlines()\n",
        "        num_line = 2\n",
        "        types = {}\n",
        "        for line in lines[2:15]:\n",
        "            for type in procedure_types_EXP:\n",
        "                for term in procedure_types_EXP[type]:\n",
        "                    words = line.split()\n",
        "                    for word in words:\n",
        "                        if word == term.lower():\n",
        "                            types[num_line] = type\n",
        "\n",
        "            num_line += 1\n",
        "        if len(types) == 0:\n",
        "            return None\n",
        "        return (min(types.items(), key=lambda x: x[0])[1])\n",
        "\n",
        "    def search_line_index(self, word):\n",
        "        \"\"\"\n",
        "        search for a given word in self.text\n",
        "        return the line index where the word found. and -1 if wasn't found\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def get_patient_name(self):\n",
        "        \"\"\"\n",
        "        Check if a given patient name is correct\n",
        "        and set the name if was't given a name\n",
        "        \"\"\"\n",
        "        if self.patient_name is None:\n",
        "            match = re.search(r'(patient|name|patient name): (\\w+\\s\\w+)', self.read_pdf.lower())\n",
        "            if match:\n",
        "                return match.group(2)\n",
        "            else:\n",
        "                return \"No name\"\n",
        "        name = self.patient_name.split()\n",
        "        i = 0\n",
        "        lines = self.get_text().splitlines()\n",
        "        for line in lines[2:15]:\n",
        "            list_line = line.split()\n",
        "            for a in name:\n",
        "                if a in list_line:\n",
        "                    i +=1\n",
        "            if i == len(name):\n",
        "                return self.patient_name\n",
        "            i = 0\n",
        "        return \"no name\"\n",
        "\n",
        "\n",
        "    #   for colab- calling ocr methods\n",
        "    def ocr_convert_pdf_to_str(self, path):\n",
        "        img_lst = self.convert_pdf_to_image_list(path)\n",
        "        str_lst = self.convert_list_of_images_to_list_of_str(img_lst)\n",
        "        txt = '\\n'.join([i for i in str_lst[1:]])\n",
        "        return txt\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8GrwoqcUZDV"
      },
      "source": [
        "OCR FUNCTIONS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtyTZ6ciUduQ"
      },
      "source": [
        "def convert_pdf_to_image_list(pdf_path):\n",
        "    \"\"\"\n",
        "        this function converts pdf to a python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        pdf_path : string\n",
        "            pdf_path is the local path of the pdf file on given machine.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images,\n",
        "            where each image corresponds to a single pdf page.\n",
        "\n",
        "        \"\"\"\n",
        "    pages = convert_from_path(pdf_path, 300)  # pages is a list of images\n",
        "    return pages\n",
        "\n",
        "\n",
        "def convert_list_of_images_to_list_of_str(img_lst):\n",
        "    \"\"\"\n",
        "        this function converts a list of images to a list of strings.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_lst : Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Python list\n",
        "            Python list of strings corresponding to img_lst.\n",
        "\n",
        "        \"\"\"\n",
        "    lst_of_str = []\n",
        "    for img in img_lst:\n",
        "        lst_of_str.append(pytesseract.image_to_string(img))\n",
        "    return lst_of_str\n",
        "\n",
        "\n",
        "def convert_list_of_images_to_list_of_xml(img_lst):\n",
        "    \"\"\"\n",
        "        this function converts a list of images to a list of xml (type=byte).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_lst : Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Python list\n",
        "            Python list of xml(type=byte) corresponding to img_lst.\n",
        "\n",
        "        \"\"\"\n",
        "    lst_of_xml = []\n",
        "    for img in img_lst:\n",
        "        lst_of_xml.append(pytesseract.image_to_pdf_or_hocr(img, extension='hocr'))  # Get HOCR output)\n",
        "    return lst_of_xml\n",
        "\n",
        "\n",
        "def convert_list_of_images_to_list_of_data(img_lst):\n",
        "    \"\"\"\n",
        "        this function converts a list of images to a list of tables of data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        img_lst : Python list of <class 'PIL.PpmImagePlugin.PpmImageFile'> images.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Python list\n",
        "            Python list of tables of data corresponding to img_lst.\n",
        "\n",
        "        \"\"\"\n",
        "    lst_of_data = []\n",
        "    for img in img_lst:\n",
        "        lst_of_data.append(pytesseract.image_to_data(img))\n",
        "    return lst_of_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuioIG84cSiz"
      },
      "source": [
        "# files creator\n",
        "running on a given path and creating CSV file with the result on document class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIiFc6c4VzA0"
      },
      "source": [
        "Callingand creating files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5UNXU8YXcsT"
      },
      "source": [
        "class file_creator:\n",
        "  \"\"\"\n",
        "  creat csv file with document indexes\n",
        "  using Dpcument classification class \n",
        "  \"\"\"\n",
        "  def __init__(self, path=None):\n",
        "    drive.mount('/content/drive')\n",
        "    # Drive path:\n",
        "    self.test_path = r'/content/drive/Shareddrives/co-op_projects/Sample documents/'\n",
        "    self.main_dir = path\n",
        "    if path == None:\n",
        "      self.main_dir = self.test_path\n",
        "    fields = ['patient_name',\n",
        "              'date_of_document',\n",
        "              'date_of_procedure',\n",
        "              'doctor_name',\n",
        "              'institution',\n",
        "              'procedure_type',\n",
        "              'num_of_pages',\n",
        "              'document_reference',\n",
        "              'Last modified',\n",
        "              'Document']\n",
        "    # rows = [[i for i in range(10)]]\n",
        "    # name of csv file\n",
        "    self.global_doc_index = self.main_dir +\"/global_doc_index.csv\"\n",
        "    \n",
        "    with open(self.global_doc_index, 'w') as self.csvfile:\n",
        "      # creating a csv writer object\n",
        "      csvwriter = csv.writer(self.csvfile)\n",
        "        \n",
        "      # writing the fields\n",
        "      csvwriter.writerow(fields)\n",
        "        \n",
        "      # writing the data rows\n",
        "      # csvwriter.writerows(rows)  \n",
        "    \n",
        "\n",
        "    self.sub_dirs = [join(self.main_dir , f) for f in listdir(self.main_dir) if not isfile(join(self.main_dir , f))]\n",
        "    \n",
        "    \n",
        "  def list_sub_dir_fullpath(self):\n",
        "    return [join(self.main_dir, f) for f in os.listdir(self.main_dir) if not isfile(join(self.main_dir, f))]\n",
        "\n",
        "  def get_list_of_only_files(self):\n",
        "    onlyfiles = [f for f in listdir(self.main_dir) if isfile(join(mypath, f))]\n",
        "    return onlyfiles\n",
        "        \n",
        "  def doc_index_to_CSV(self, file):\n",
        "    pass\n",
        "  \n",
        "  def run(self):\n",
        "    # each type\n",
        "    for dir in self.sub_dirs:\n",
        "      # doc dirs\n",
        "      doc_sub_dir = [join(dir , f) for f in listdir(dir) if not isfile(join(dir,f)) and not f.endswith(\".ipynb_checkpoints\") and not f.endswith(\".pdf\")]\n",
        "      doc_names = [f for f in listdir(dir) if not isfile(join(dir,f)) and not f.endswith(\".ipynb_checkpoints\") and not f.endswith(\".pdf\")]\n",
        "      for doc in doc_sub_dir:\n",
        "        # print(doc)\n",
        "        # print(doc_names[doc_sub_dir.index(doc)])\n",
        "        \n",
        "        #current ocr_txt\n",
        "        onlyTxtFiles = [f for f in listdir(doc) if f.endswith(\".txt\")]\n",
        "         \n",
        "        if \"OCR_txt_all.txt\" in onlyTxtFiles:\n",
        "          ocr_file = doc+\"/OCR_txt_all.txt\"\n",
        "          with open(ocr_file, 'r') as file:\n",
        "              ocr_txt =\"\".join(file.readlines())\n",
        "          \n",
        "          doc_class = DocumentClassification(doc+\".pdf\", file=ocr_txt, patient_name=None, mode='TXT')\n",
        "          indexes = doc_class.doc_index\n",
        "          now = datetime.now()\n",
        "          # dd/mm/YY H:M:S\n",
        "          dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "          indexes[\"Last modified\"] = dt_string\n",
        "          # TBC: write in the current doc path \"doc_index.csv\"\n",
        "          indexes[\"Document\"] = doc_names[doc_sub_dir.index(doc)]\n",
        "\n",
        "          # field names\n",
        "          fields = [key for key in indexes.keys()]\n",
        "            \n",
        "          # data rows of csv file\n",
        "          rows = [[val for val in indexes.values()]]\n",
        "            \n",
        "          # name of csv file\n",
        "          filename = doc+\"/doc_index.csv\"\n",
        "          print(\"creating\"+indexes[\"Document\"]+ \"  File\")\n",
        "          # writing to csv file\n",
        "          with open(filename, 'w') as csvfile:\n",
        "            # creating a csv writer object\n",
        "            csvwriter = csv.writer(csvfile)\n",
        "              \n",
        "            # writing the fields\n",
        "            csvwriter.writerow(fields)\n",
        "              \n",
        "            # writing the data rows\n",
        "            csvwriter.writerows(rows)\n",
        "          #  ADD row with the \"indexes\" to the global doc index\n",
        "          global_csv_row = [val for val in indexes.values()]\n",
        "          with open(self.global_doc_index, 'a') as csvfile:\n",
        "            # creating a csv writer object\n",
        "            csvwriter = csv.writer(csvfile)\n",
        "            # writing the current index\n",
        "            csvwriter.writerow(global_csv_row)\n",
        "\n",
        "\n",
        "        # onlyTxtFiles = [f for f in listdir(p) if isfile(join(p, f)) and  f.endswith(\".txt\")]\n",
        "        # # working_on_first_txt_file\n",
        "        # working_on_first_txt_file = p+\"/\"+onlyTxtFiles[0]\n",
        "        # print(working_on_first_txt_file)\n",
        "        # with open(working_on_first_txt_file, 'r') as file:\n",
        "\n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O19Jo-HNV3du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67ebeb2-5859-4d23-b908-70316283e88e"
      },
      "source": [
        "a=file_creator()\n",
        "print(a.run())"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "creatingCT 2020-1-20  File\n",
            "creatingCT19  File\n",
            "creatingCT  2019-7-16  File\n",
            "creatingCT 2020-3-26  File\n",
            "creatingMRI 2019-1-29  File\n",
            "creatingMRI 2017-12-18  File\n",
            "creatingCT chest, abdomen, pelvis 07052020  File\n",
            "creating01032020 CT-AbdomenPelvis wLiver Triphasic  File\n",
            "creating01092020 Radiology  File\n",
            "creating01102018 CT CHABDPEL WCON  File\n",
            "creating04162019 NM-NM SIRSPH NM THRPY-ADM BREMSLIV SPCT  File\n",
            "creating06132018 MR-Liver wwo Con  File\n",
            "creating10212019 PET-NECK.CAP - FDG  File\n",
            "creating10242017 MR RECTUM WWO CONTRAST  File\n",
            "creating12272019 US-Extremity Lower Veins Bilateral  File\n",
            "creating20160408_imaging_SM_1  File\n",
            "creatingPET CT 5.27.2016  File\n",
            "creatingAC PET_CT 2.19.2020  File\n",
            "creatingAC CXR 11.2.2020  File\n",
            "creatingCXR 12.11.2020  File\n",
            "creatingAC PET_CT 9_19_2019  File\n",
            "creatingAC CXR 6.24.2019  File\n",
            "creatingCXR 2.11.2021  File\n",
            "creatingCT chest abd 3.25.2019  File\n",
            "creatingPET CT 5.27.2016_quality  File\n",
            "creatingAC PET_CT 9_19_2019_quality  File\n",
            "creatingCT Scan 3-15-21  File\n",
            "creatingBrain MRI 3-15-21  File\n",
            "creating20210408_RP_1_imaging_int_p1-2  File\n",
            "creatingEM imaging  File\n",
            "creatingEM imaging MRI  File\n",
            "creatingCB imaging1  File\n",
            "creatingCB imaging2  File\n",
            "creatingChristenson, Alan Date of Birth  File\n",
            "creatingAAC labs 9.27.19  File\n",
            "creatingMSK lab results 2  File\n",
            "creatingBD_20150803  File\n",
            "creatingxyz  File\n",
            "creating2020-08-04 19-50  File\n",
            "creatingAC Labs 2.9.2021  File\n",
            "creatingLIPASE - Details 3-15-21  File\n",
            "creatingAMYLASE SERUM - Details 3-15-21  File\n",
            "creatingCREATINE KINASE - Details 3-15-21  File\n",
            "creatingCOMPREHENSIVE METABOLIC PANEL - Details 3-15-21  File\n",
            "creatingCARCINOEMBRYONIC ANTIGEN  3-15-21  File\n",
            "creatingCBC, ONCOLOGY - Details 3-15-21  File\n",
            "creatingCANCER ANTIGEN 125 - Details 3-15-21  File\n",
            "creatingAC 2.8.21 iron studies  File\n",
            "creatingAC iron studies 1.3.2020  File\n",
            "creatingMSK lab results_1  File\n",
            "creatingAC B12 2.8.2021  File\n",
            "creatingAC 5.14.2019 Labs  File\n",
            "creatingAC CBC 2.8.21  File\n",
            "creatingAC Hs-CRP 2.8.2021  File\n",
            "creatingAC CMP 11.2.2020  File\n",
            "creatingAC 6.20.19 CBC  File\n",
            "creatingAC 7.11.2020 CBC  File\n",
            "creatingCAtalyst Flyer  File\n",
            "creatingblood_test_2  File\n",
            "creatingBlood test SM_1  File\n",
            "creatingCB blood1  File\n",
            "creatingAlan Christenson - 11.4.2016 CPE  File\n",
            "creatingAC 6.24.2019 pulm  File\n",
            "creatingAC 1.23.2018 Dr. Swanson  File\n",
            "creatingAlan Christenson - 2.23.2018  File\n",
            "creatingAC 11.2.17 rad onc note  File\n",
            "creatingAC intake rad onc 5.26.18  File\n",
            "creatingAC 4.27.17 rad onc  File\n",
            "creatingAC 1.26.17 rad onc  File\n",
            "creatingAC follow up rad onc note  File\n",
            "creatingEM dr note  File\n",
            "creatingCB drn1  File\n",
            "creatingCB drn2  File\n",
            "creatingCB drn3  File\n",
            "creating2016.4.14. Brigham slide review  File\n",
            "creating2019.6.26. endobronchial bx  File\n",
            "creating2016.4.15 pleural and LN bx  File\n",
            "creating05.16.2019 Surgical Pathology  File\n",
            "creating02.14.2018 Surgical Pathology  File\n",
            "creating11.11.2019 Endo-Ileoscopy  File\n",
            "creating20160420_surg_note1_SM_1  File\n",
            "creating2016.3.10 surg path  File\n",
            "creatingEM surgery 0318  File\n",
            "creatingEM surgery 2  File\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDUMBUTpc0Mv"
      },
      "source": [
        "# TESTER:: RUN THE PROGRAM:: MAIN SECTION!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jy1DKUnRgSc"
      },
      "source": [
        "a=file_creator()\n",
        "a.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmMlhhc8ctv3"
      },
      "source": [
        "# draft --only for develop!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdN5b2N8WP4J"
      },
      "source": [
        "draft cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMqzfgxyc6dT",
        "outputId": "b20106b8-19f2-46ab-a5c0-4e8b53137bb6"
      },
      "source": [
        "# a = DocumentClassification(r\"C:\\Users\\ehudb\\PycharmProjects\\nixio test\\Sample documents\\Pathology\\2016.4.14. Brigham slide review.pdf\")\n",
        "# # print(a.print_indexs)\n",
        "# print(yaml.dump(a.get_doc_index()))\n",
        "# a.close_file()\n",
        "\n",
        "a = DocumentClassification(r\"/content/drive/Shareddrives/co-op_projects/Sample documents/Pathology/2019.6.26. endobronchial bx.pdf\" , mode=\"PDF\")\n",
        "#print(a._print_index())\n",
        "print(yaml.dump(a.get_doc_index()))\n",
        "# print(a.read_pdf)\n",
        "\n",
        "a.close_file()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{date_of_document: null, date_of_procedure: null, doctor_name: 'Chalker, Richard Bruce,\n",
            "    MD', document_reference: /content/drive/Shareddrives/co-op_projects/Sample documents/Pathology/2019.6.26.\n",
            "    endobronchial bx.pdf, institution: null, num_of_pages: 3, patient_name: No name,\n",
            "  procedure_type: Pathology and Surgery}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6kJn9HmWVLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bdb853-0b16-4a83-810b-0ebe9db6dbd2"
      },
      "source": [
        "# working cell:\n",
        "test_path = r'/content/drive/Shareddrives/co-op_projects/Sample documents/'\n",
        "\n",
        "sub_dir = [join(test_path , f) for f in listdir(test_path) if not isfile(join(test_path , f))]\n",
        "\n",
        "doc = r\"/content/drive/Shareddrives/co-op_projects/Sample documents/Imaging/EM imaging\"\n",
        "# print(listdir(p))\n",
        "\n",
        "# ocr_txt\n",
        "ocr_file = p+\"/OCR_txt_all.txt\"\n",
        "with open(ocr_file, 'r') as file:\n",
        "    ocr_txt =\" \".join(file.readlines())\n",
        "r = DocumentClassification(p+\".pdf\", file=ocr_txt, patient_name=None, mode='TXT')\n",
        "indexes = r.doc_index\n",
        "now = datetime.now()\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "indexes[\"Last modified\"] = dt_string\n",
        "indexes[\"Document\"] = doc\n",
        "# print(indexes.keys)\n",
        "print(indexes)\n",
        "\n",
        "\n",
        "#write in the current doc path \"doc_index.csv\"\n",
        "\n",
        "# field names\n",
        "fields = [key for key in indexes.keys()]\n",
        "  \n",
        "# data rows of csv file\n",
        "rows = [[val for val in indexes.values()]]\n",
        "  \n",
        "# name of csv file\n",
        "filename = doc+\"/doc_index.csv\"\n",
        "  \n",
        "# writing to csv file\n",
        "with open(filename, 'w') as csvfile:\n",
        "  # creating a csv writer object\n",
        "  csvwriter = csv.writer(csvfile)\n",
        "    \n",
        "  # writing the fields\n",
        "  csvwriter.writerow(fields)\n",
        "    \n",
        "  # writing the data rows\n",
        "  csvwriter.writerows(rows)\n",
        "  \n",
        "  # TBC: ADD row with the \"indexes\" to the global doc index\n",
        "\n",
        "\n",
        "# a = DocumentClassification(p+\".pdf\" , mode=\"PDF\")\n",
        "# #print(a._print_index())\n",
        "# print(yaml.dump(a.get_doc_index()))"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'patient_name': 'No name', 'date_of_document': None, 'date_of_procedure': None, 'doctor_name': 'JOEL SHEINFELD, MD', 'institution': None, 'procedure_type': 'Imaging', 'num_of_pages': 0, 'document_reference': '/content/drive/Shareddrives/co-op_projects/Sample documents/Imaging/EM imaging.pdf', 'Last modified': '08/06/2021 17:45:21', 'Document': '/content/drive/Shareddrives/co-op_projects/Sample documents/Imaging/EM imaging'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYQYR_pTMyaC",
        "outputId": "2939cd44-6d71-4180-a68e-09d85eb42f3c"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# datetime object containing current date and time\n",
        "now = datetime.now()\n",
        " \n",
        "print(\"now =\", now)\n",
        "\n",
        "# dd/mm/YY H:M:S\n",
        "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "print(\"date and time =\", dt_string)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now = 2021-06-08 15:17:28.055767\n",
            "date and time = 08/06/2021 15:17:28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujkaWPHzQKqg"
      },
      "source": [
        "with open('indexes.csv', 'w') as f:\n",
        "    for key in indexes.keys():\n",
        "        f.write(\"%s, %s\\n\" % (key, indexes[key]))"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHM4qFcWk5RW"
      },
      "source": [
        "# Python program to demonstrate\n",
        "# writing to CSV\n",
        "\n",
        "\n",
        "import csv\n",
        "\t\n",
        "# field names\n",
        "fields = [key for key in indexes.keys()]\n",
        "\t\n",
        "# data rows of csv file\n",
        "rows = [[test for i in range(10)]]\n",
        "\t\n",
        "# name of csv file\n",
        "filename = \"doc_index.csv\"\n",
        "\t\n",
        "# writing to csv file\n",
        "with open(filename, 'w') as csvfile:\n",
        "\t# creating a csv writer object\n",
        "\tcsvwriter = csv.writer(csvfile)\n",
        "\t\t\n",
        "\t# writing the fields\n",
        "\tcsvwriter.writerow(fields)\n",
        "\t\t\n",
        "\t# writing the data rows\n",
        "\tcsvwriter.writerows(rows)\n"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLRI66t9xaio",
        "outputId": "8ee91680-43ae-4f2c-cd0d-9ff5b3fb5d3c"
      },
      "source": [
        "fields = [key for key in indexes.keys()]\n",
        "len(fields)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_FR4lXFhCdT",
        "outputId": "03510bb9-75b4-4851-fabe-901ce6ce3fe7"
      },
      "source": [
        "fields = [val for val in indexes.values()]\n",
        "fields\n",
        "  "
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['No name',\n",
              " None,\n",
              " None,\n",
              " 'JOEL SHEINFELD, MD',\n",
              " None,\n",
              " 'Imaging',\n",
              " 0,\n",
              " '/content/drive/Shareddrives/co-op_projects/Sample documents/Imaging/EM imaging.pdf',\n",
              " '08/06/2021 16:55:01']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRRJzeKSNdUR"
      },
      "source": [
        "indexes\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCOIzNxRHncI"
      },
      "source": [
        "print(ocr_txt)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}